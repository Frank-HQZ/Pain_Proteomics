{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file 'UKB_olink_proteins.csv' into a DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv('UKB_olink_proteins.csv')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a909871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes df and df1 based on the 'eid' column\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, average_precision_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings(('ignore'))\n",
    "\n",
    "\n",
    "df1= pd.read_csv('pain_onset.csv')\n",
    "\n",
    "mydf1 = pd.merge(df, df1, how='inner', on=['eid'])\n",
    "\n",
    "mydf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb11d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -9 in column A with the vacancy value NaN\n",
    "mydf1['back'].replace(-9, np.nan, inplace=True)\n",
    "\n",
    "mydf2=mydf1\n",
    "\n",
    "mydf2.head()\n",
    "\n",
    "# Delete the row with the vacancy value in column A\n",
    "mydf2.dropna(subset=['back'], inplace=True)\n",
    "\n",
    "mydf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specified features from the dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(('ignore'))\n",
    "\n",
    "rm_f1 = ['eid', 'ins_index']\n",
    "rm_HES = ['head', 'face', 'neck', 'back', 'stomach','hip','knee']\n",
    "rm_f = rm_f1 + rm_HES\n",
    "\n",
    "X = mydf2.drop(rm_f, axis=1)\n",
    "y = mydf2['head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform stratified K-fold cross-validation with 5 splits, and shuffle the data\n",
    "mykf = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle = True)\n",
    "\n",
    "my_params = {'n_estimators': 500,\n",
    "             'max_depth': 15,\n",
    "             'num_leaves': 10,\n",
    "             'subsample': 0.7,\n",
    "             'learning_rate': 0.01,\n",
    "             'colsample_bytree': 0.7}\n",
    "\n",
    "def normal_imp(mydict):\n",
    "    mysum = sum(mydict.values())\n",
    "    mykeys = mydict.keys()\n",
    "    for key in mykeys:\n",
    "        mydict[key] = mydict[key]/mysum\n",
    "    return mydict\n",
    "\n",
    "tg_imp_cv = Counter()\n",
    "tc_imp_cv = Counter()\n",
    "\n",
    "for train_idx, test_idx in mykf.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_idx,:], y.iloc[train_idx]\n",
    "    my_lgb = LGBMClassifier(objective = 'binary',\n",
    "                           metric = 'auc',\n",
    "                           is_unbalance = True,\n",
    "                           verbosity = 1, seed = 2020)\n",
    "    my_lgb.set_params(**my_params)\n",
    "    my_lgb.fit(X_train, y_train)\n",
    "    totalgain_imp = my_lgb.booster_.feature_importance(importance_type='gain')\n",
    "    totalgain_imp = dict(zip(my_lgb.booster_.feature_name(), totalgain_imp.tolist()))\n",
    "    totalcover_imp = my_lgb.booster_.feature_importance(importance_type='split')\n",
    "    totalcover_imp = dict(zip(my_lgb.booster_.feature_name(), totalcover_imp.tolist()))\n",
    "    tg_imp_cv += Counter(normal_imp(totalgain_imp))\n",
    "    tc_imp_cv += Counter(normal_imp(totalcover_imp))\n",
    "\n",
    "\n",
    "tg_imp_df = pd.DataFrame({'Features': list(tg_imp_cv.keys()),\n",
    "                          'TotalGain_cv': list(tg_imp_cv.values())})\n",
    "\n",
    "tc_imp_df = pd.DataFrame({'Features': list(tc_imp_cv.keys()),\n",
    "                          'TotalCover_cv': list(tc_imp_cv.values())})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_imp_df = pd.merge(left = tc_imp_df, right = tg_imp_df, how = 'left')\n",
    "my_imp_df.sort_values(by = 'TotalGain_cv', ascending = False, inplace = True)\n",
    "\n",
    "my_imp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e6938",
   "metadata": {},
   "outputs": [],
   "source": [
    "myout=my_imp_df\n",
    "myout.to_csv('result_pain/back_s01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adadfa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, average_precision_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings(('ignore'))\n",
    "\n",
    "df_f = pd.read_csv('result_pain/back_s01.csv')\n",
    "df_f.sort_values(by = 'TotalCover_cv', ascending = False, inplace = True)\n",
    "df_f1 = df_f.head(100)\n",
    "my_f = df_f1['Features'].to_list()\n",
    "\n",
    "X = mydf2[my_f]\n",
    "y = mydf2['back']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a LightGBM classifier using stratified K-fold cross-validation with 5 splits, and calculate AUC metrics\n",
    "mykf = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle = True)\n",
    "\n",
    "\n",
    "my_params = {'n_estimators': 875,\n",
    "             'max_depth': 16,\n",
    "             'num_leaves': 11,\n",
    "             'subsample': 0.7,\n",
    "             'learning_rate': 0.01,\n",
    "             'colsample_bytree': 0.7}\n",
    "\n",
    "\n",
    "tmp_f, AUC_cv_lst= [], []\n",
    "\n",
    "for f in my_f:\n",
    "    tmp_f.append(f)\n",
    "    my_X = X[tmp_f]\n",
    "    AUC_cv = []\n",
    "    for train_idx, test_idx in mykf.split(my_X, y):\n",
    "        X_train, X_test = my_X.iloc[train_idx, :], my_X.iloc[test_idx, :]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        my_lgb = LGBMClassifier(objective='binary',\n",
    "                                metric='auc',\n",
    "                                is_unbalance=True,\n",
    "                                n_jobs=4,\n",
    "                                verbosity=-1, seed=2022)\n",
    "        my_lgb.set_params(**my_params)\n",
    "        my_lgb.fit(X_train, y_train)\n",
    "        y_pred_prob = my_lgb.predict_proba(X_test)[:, 1]\n",
    "        AUC_cv.append(roc_auc_score(y_test, y_pred_prob))\n",
    "    tmp_out = np.array([np.mean(AUC_cv), np.std(AUC_cv)] + AUC_cv)\n",
    "    AUC_cv_lst.append(np.round(tmp_out, 3))\n",
    "    print((f, tmp_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c9e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_df = pd.concat((pd.DataFrame({'Features':tmp_f}), pd.DataFrame(AUC_cv_lst)), axis = 1)\n",
    "\n",
    "AUC_df.head()\n",
    "\n",
    "myout2=AUC_df\n",
    "\n",
    "myout2.columns = ['Features', 'AUC_mean', 'AUC_std', 'AUC0', 'AUC1', 'AUC2', 'AUC3', 'AUC4']\n",
    "\n",
    "myout2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "myout2.to_csv('result_pain/back_s02.csv')\n",
    "df_f2 = df_f.head(50)\n",
    "df_f2.to_csv('result_pain/back_s001.csv')\n",
    "\n",
    "df_f3 = pd.read_csv('result_pain/back_s02.csv')\n",
    "df_f3 = df_f3.head(50)\n",
    "df_f3.shape\n",
    "df_f3.to_csv('result_pain/back_s002.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd244156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictor importance (Fimp) and cumulative AUC values for prediction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "fimp_s03 = pd.read_csv('result_pain/back_s001.csv')\n",
    "fimp_s03.sort_values(by = 'TotalCover_cv', ascending = False, inplace = True)\n",
    "fimp_s04 = pd.read_csv('result_pain/back_s002.csv')\n",
    "fimp_s04['f_idx'] = fimp_s04['Unnamed: 0'] + 1\n",
    "mylabel = (fimp_s03['Features'])\n",
    "\n",
    "fimp_tc = pd.DataFrame(zip(fimp_s03['TotalCover_cv'], mylabel), columns=['Fimp','Feature'])\n",
    "fimp_tc = pd.concat((fimp_s04[['f_idx', 'AUC_mean', 'AUC0', 'AUC1', 'AUC2', 'AUC3', 'AUC4', 'AUC_std']], fimp_tc), axis = 1)\n",
    "fimp_tc['AUC_lower'] = fimp_tc['AUC_mean'] - 1.96*fimp_tc['AUC_std']\n",
    "fimp_tc['AUC_upper'] = fimp_tc['AUC_mean'] + 1.96*fimp_tc['AUC_std']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (18, 7))\n",
    "palette = sns.color_palette(\"Blues\",n_colors=len(fimp_tc))\n",
    "palette.reverse()\n",
    "sns.barplot(ax=ax, x = \"Feature\", y = \"Fimp\", palette=palette, data=fimp_tc.sort_values(by=\"Fimp\", ascending=False))\n",
    "ax.set_ylim([0, 0.1])\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_xticklabels(fimp_tc['Feature'], rotation=30, fontsize=12, horizontalalignment='right')\n",
    "nb_f = 23\n",
    "my_col = ['r']*nb_f + ['k']*(len(fimp_tc)-nb_f)\n",
    "for ticklabel, tickcolor in zip(plt.gca().get_xticklabels(), my_col):\n",
    "    ticklabel.set_color(tickcolor)\n",
    "ax.set_ylabel('Predictor Importance', weight='bold', fontsize=18)\n",
    "#ax.set_title('10-year incident AD', y=1.0, pad=-25, weight='bold', fontsize=24)\n",
    "ax.set_xlabel('')\n",
    "ax.grid(which='minor', alpha=0.2, linestyle=':')\n",
    "ax.grid(which='major', alpha=0.5,  linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "#ax2.plot(fimp_tc['f_idx']-1, fimp_tc['AUC0'], 'mediumvioletred', alpha = 0.15, marker='o')\n",
    "#ax2.plot(fimp_tc['f_idx']-1, fimp_tc['AUC1'], 'mediumvioletred', alpha = 0.15, marker='o')\n",
    "#ax2.plot(fimp_tc['f_idx']-1, fimp_tc['AUC2'], 'mediumvioletred', alpha = 0.15, marker='o')\n",
    "#ax2.plot(fimp_tc['f_idx']-1, fimp_tc['AUC3'], 'mediumvioletred', alpha = 0.15, marker='o')\n",
    "#ax2.plot(fimp_tc['f_idx']-1, fimp_tc['AUC4'], 'mediumvioletred', alpha = 0.15, marker='o')\n",
    "ax2.plot(np.arange(nb_f+1), fimp_tc['AUC_mean'][:nb_f+1], 'red', alpha = 0.8, marker='o')\n",
    "ax2.plot(np.arange(nb_f+1, len(fimp_tc)), fimp_tc['AUC_mean'][nb_f+1:], 'black', alpha = 0.8, marker='o')\n",
    "ax2.plot([nb_f, nb_f+1], fimp_tc['AUC_mean'][nb_f:nb_f+2], 'black', alpha = 0.8, marker='o')\n",
    "plt.fill_between(fimp_tc['f_idx']-1, fimp_tc['AUC_lower'], fimp_tc['AUC_upper'], color = 'tomato', alpha = 0.2)\n",
    "ax2.set_ylabel('Cumulative AUC', weight='bold', fontsize=18)\n",
    "ax2.tick_params(axis='y', labelsize=14)\n",
    "#ax2.set_yticklabels([0.78, 0.80, 0.82, 0.84, 0.86], fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.xlim([-.6, len(fimp_tc)-.2])\n",
    "plt.savefig('result_pain/Cover_Imp_back.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean ROC curve \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "\n",
    "# my_X is the feature data, y is the label data, and my_params is the model parameter\n",
    "mykf = StratifiedKFold(n_splits = 5, random_state = 2022, shuffle = True)\n",
    "my_params = {'n_estimators': 1000,\n",
    "             'max_depth': 5,\n",
    "             'num_leaves': 30,\n",
    "             'subsample': 0.7,\n",
    "             'learning_rate': 0.01,\n",
    "             'colsample_bytree': 0.7}\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "# Loop through the feature data\n",
    "for train_idx, test_idx in mykf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx, :], X.iloc[test_idx, :]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    my_lgb = LGBMClassifier(objective='binary', metric='auc', is_unbalance=True, n_jobs=4, verbosity=-1, seed=2022)\n",
    "    my_lgb.set_params(**my_params)\n",
    "    my_lgb.fit(X_train, y_train)\n",
    "    y_pred_prob = my_lgb.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "# Calculate the average ROC curve and AUC values\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = np.mean(aucs)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "\n",
    "tprs_upper = np.minimum(mean_tpr + 2*std_auc, 1)\n",
    "tprs_lower = mean_tpr - 2*std_auc\n",
    "\n",
    "plt.plot(mean_fpr,  mean_tpr, linewidth = 5,label=r'Mean ROC (AUC = %0.2f)' % (mean_auc))\n",
    "\n",
    "plt.legend(loc=\"lower right\",fontsize = 20)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--',linewidth=5 )\n",
    "plt.xlim([-0.0, 1.0])\n",
    "plt.ylim([-0.0, 1.0])\n",
    "plt.ylabel('True Positive Rate', fontsize = 30)\n",
    "plt.xlabel('False Positive Rate', fontsize = 30)\n",
    "\n",
    "plt.yticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], fontsize = 16)\n",
    "plt.xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], fontsize = 16)\n",
    "plt.grid(which='minor', alpha=0.2, linestyle=':')\n",
    "plt.grid(which='major', alpha=0.5,  linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig('result_pain/ROC_back.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
